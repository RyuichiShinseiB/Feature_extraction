{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import polars as pl\n",
    "\n",
    "import joblib\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from PIL import Image\n",
    "from pathlib import Path\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.mixture import BayesianGaussianMixture\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from scipy.stats import rankdata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scatter_each_classes(data, class_labels, rank, markers, colors, xylabel, facecolor='valid', scatter_classe=(None,)):\n",
    "    labels = scatter_classe if not (None in scatter_classe) else np.unique(class_labels)\n",
    "    markers = markers if markers is not None else ['o'] * np.unique(class_labels).shape[0]\n",
    "    colors = [plt.get_cmap('tab10')(i) for i in range(10)] if colors == 'tab10' else colors\n",
    "    print(markers)\n",
    "    \n",
    "    if isinstance(colors, matplotlib.colors.LinearSegmentedColormap):\n",
    "        for l, r in zip(labels, rank):\n",
    "            if (facecolor == 'None') and (markers[l] != 'x'):\n",
    "                plt.scatter(data[class_labels==l, 0], data[class_labels==l, 1], edgecolors=colors(l / len(labels)), label=f'cluster{l}', marker=markers[l], facecolor=facecolor, zorder=r)\n",
    "            else:\n",
    "                plt.scatter(data[class_labels==l, 0], data[class_labels==l, 1], c=colors(l / len(labels)), label=f'cluster{l}', marker=markers[l], zorder=r)\n",
    "    else:\n",
    "        for l, r in zip(labels, rank):\n",
    "            if (facecolor == 'None') and (markers[l] != 'x'):\n",
    "                plt.scatter(data[class_labels==l, 0], data[class_labels==l, 1], edgecolors=colors[l], label=f'cluster{l}', marker=markers[l], facecolor=facecolor, zorder=r)\n",
    "            else:\n",
    "                plt.scatter(data[class_labels==l, 0], data[class_labels==l, 1], c=colors[l], label=f'cluster{l}', marker=markers[l], zorder=r)\n",
    "\n",
    "    plt.xlabel(xylabel[0])\n",
    "    plt.ylabel(xylabel[1])\n",
    "    plt.legend(loc='upper left', bbox_to_anchor=(1,1))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_images(imgs, n_col, n_row, padding):\n",
    "    w, h = imgs[0].size\n",
    "    w_with_pad = w + padding\n",
    "    h_with_pad = h + padding\n",
    "    W = (w_with_pad) * n_col + padding\n",
    "    H = (h_with_pad) * n_row + padding\n",
    "\n",
    "    dst = Image.new('L', (W, H))\n",
    "    iter_imgs = iter(imgs)\n",
    "    for j in range(n_row):\n",
    "        for i in range(n_col):\n",
    "            img = next(iter_imgs)\n",
    "            dst.paste(img, (padding + w_with_pad * i, padding + h_with_pad * j))\n",
    "    return dst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_path_from_df(row):\n",
    "    return Path(f\"{row['dirname']}/{row['filename']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_concat_and_imshow(df, labels, colrow, image_root):\n",
    "    concat_imgs = []\n",
    "    num_labels = len(np.unique(labels))\n",
    "    for l in np.unique(labels):\n",
    "        imgs = []\n",
    "        df_ = df[labels == l].sample(colrow[0] * colrow[1])\n",
    "        df_.apply(make_path_from_df, axis=1)\n",
    "        for p in df_.apply(make_path_from_df, axis=1):\n",
    "            imgs.append(Image.open(image_root / p))\n",
    "        concat_imgs.append(concat_images(imgs, colrow[0], colrow[1], 2))\n",
    "\n",
    "    fig = plt.figure(figsize=(10,11))\n",
    "    axes = list(map(lambda f: fig.add_subplot(1,num_labels,f+1), range(num_labels)))\n",
    "    for i in range(num_labels):\n",
    "        axes[i].imshow(concat_imgs[i], )\n",
    "        axes[i].set_title(f'cluster {i}')\n",
    "        axes[i].axis('off')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    return concat_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:brown', 'tab:pink', 'tab:gray', 'tab:olive', 'tab:cyan']\n",
    "markers = ['s', 'D', 'o', 'p', '*', 'h', 'D', '8', 'v', 'x']\n",
    "\n",
    "feature_csv_path = \"/home/shinsei/MyResearchs/feat_extrc/reports/features/SimpleCAE32/2023-07-07/12-15-24/features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stds = StandardScaler()\n",
    "# df_train = pd.read_csv(feature_csv_pardir / 'check_data' / check_data_feature_csv_name)\n",
    "df_train = pl.read_csv(feature_csv_path)\n",
    "X_train = df_train.\n",
    "X_train_std = stds.fit_transform(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_features)\n",
    "X_train_pca = pca.fit_transform(X_train_std)\n",
    "cumsum_contrb_rate = pca.explained_variance_ratio_.cumsum()\n",
    "\n",
    "plt.plot(range(n_features+1), [0]+list(cumsum_contrb_rate))\n",
    "plt.xlabel('Number of principal components')\n",
    "plt.ylabel('Cumulative contribution rate')\n",
    "plt.yticks(np.arange(0., 1.1, 0.1))\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
